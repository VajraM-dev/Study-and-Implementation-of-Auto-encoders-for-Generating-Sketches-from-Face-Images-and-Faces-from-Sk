{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#import all the required libraries\nimport numpy as np \nimport pandas as pd \nimport os\nfrom tqdm import tqdm \nimport cv2\nfrom keras.preprocessing.image import img_to_array\nimport matplotlib.pyplot as plt\nimport keras \nimport tensorflow\nimport tensorflow as tf\nfrom tensorflow.keras import Input, Model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Reshape, GaussianNoise, Conv2D, MaxPooling2D, UpSampling2D, Add, Input, Dropout\nfrom tensorflow.keras.optimizers import SGD, Adam\nfrom keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport re\nfrom skimage.metrics import structural_similarity\ntensorflow.random.set_seed(0)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-25T13:02:45.480446Z","iopub.execute_input":"2022-02-25T13:02:45.481098Z","iopub.status.idle":"2022-02-25T13:02:51.472134Z","shell.execute_reply.started":"2022-02-25T13:02:45.480978Z","shell.execute_reply":"2022-02-25T13:02:51.471417Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# set the path for the image directories\n# for using in google colab please upload the data given along with the notebook to colab.\n# after uploading please change the data variable to appropriate directory.\ndata = \"../input/dataset1/train\"\n\nphotos = data+\"/photos\"\nsketches = data+\"/sketches\"\n\nprint(os.listdir(photos)[0])\nprint(os.listdir(sketches)[0])","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:02:51.473731Z","iopub.execute_input":"2022-02-25T13:02:51.474008Z","iopub.status.idle":"2022-02-25T13:02:51.570820Z","shell.execute_reply.started":"2022-02-25T13:02:51.473971Z","shell.execute_reply":"2022-02-25T13:02:51.570079Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# sort the photos with their names so that the right images match each other.\n# these two lists store the paths of images and sketches which are ordered.\nphoto_paths_sorted = []\nsketches_paths_sorted = []\n\n# sortFiles function sorts the files.\ndef sortFiles(path1, path2):\n  list_of_photos = sorted( filter( lambda x: os.path.isfile(os.path.join(path1, x)),\n                        os.listdir(path1) ) )\n  \n  list_of_sketches = sorted( filter( lambda x: os.path.isfile(os.path.join(path2, x)),\n                        os.listdir(path2) ) )\n  for file_name in list_of_photos:\n    #print(file_name)\n    photo_paths_sorted.append(file_name)\n\n  for file_name in list_of_sketches:\n    #print(file_name)\n    sketches_paths_sorted.append(file_name)\n\nsortFiles(photos, sketches)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:02:51.572322Z","iopub.execute_input":"2022-02-25T13:02:51.572613Z","iopub.status.idle":"2022-02-25T13:02:51.581821Z","shell.execute_reply.started":"2022-02-25T13:02:51.572578Z","shell.execute_reply":"2022-02-25T13:02:51.581143Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# this cell augments the data.\n# this function augements the images, converts and stores them in arrays.\ndef photoarray(paths):\n  array = []\n    #this size will be used to reshape the images to SIZE dimensions.\n  SIZE = 256\n    #for each image perform the below transformations\n  for i in paths:\n    # read the images\n    image = cv2.imread(photos+\"/\"+i,1)\n    # convert them to RGB\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    # resize the images\n    image = cv2.resize(image, (SIZE, SIZE))\n    # normalize the data\n    image = image.astype('float32') / 255.0\n    # convert the images to arrays. \n    array.append(img_to_array(image))\n    # flip the image\n    img1 = cv2.flip(image,1)\n    # add to array\n    array.append(img_to_array(img1))\n    # flip the image\n    img2 = cv2.flip(image,-1)\n    # add to the array\n    array.append(img_to_array(img2))\n    img3 = cv2.flip(image,-1)\n    img3 = cv2.flip(img3,1)\n    array.append(img_to_array(img3))\n    # rotate the images clockwise\n    img4 = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n    # add to array\n    array.append(img_to_array(img4))\n    img5 = cv2.flip(img4,1)\n    array.append(img_to_array(img5))\n    # rotate the images counterclockwise\n    img6 = cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n    # add to array\n    array.append(img_to_array(img6))\n    img7 = cv2.flip(img6,1)\n    array.append(img_to_array(img7))\n    \n    # return the array\n  return array\n\n# same transformations are then performed for sketches.\ndef sketcharray(paths):\n  array = []\n  SIZE = 256\n  for i in paths:\n    image = cv2.imread(sketches+\"/\"+i,1)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, (SIZE, SIZE))\n    image = image.astype('float32') / 255.0\n    array.append(img_to_array(image))\n    img1 = cv2.flip(image,1)\n    array.append(img_to_array(img1))\n    img2 = cv2.flip(image,-1)\n    array.append(img_to_array(img2))\n    img3 = cv2.flip(image,-1)\n    img3 = cv2.flip(img3,1)\n    array.append(img_to_array(img3))\n    img4 = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n    array.append(img_to_array(img4))\n    img5 = cv2.flip(img4,1)\n    array.append(img_to_array(img5))\n    img6 = cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n    array.append(img_to_array(img6))\n    img7 = cv2.flip(img6,1)\n    array.append(img_to_array(img7))\n\n  return array\n\n# this functions makes sure right paths are provided to convert the images and sketches to arrays\ndef covertToArrays(photo_paths, sketches_path):\n  image_arrays = photoarray(photo_paths)\n  sketch_arrays = sketcharray(sketches_path)\n\n  return image_arrays, sketch_arrays\n\nimage_arrays, sketch_arrays = covertToArrays(photo_paths_sorted, sketches_paths_sorted)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:02:51.584807Z","iopub.execute_input":"2022-02-25T13:02:51.585193Z","iopub.status.idle":"2022-02-25T13:02:53.612931Z","shell.execute_reply.started":"2022-02-25T13:02:51.585157Z","shell.execute_reply":"2022-02-25T13:02:53.612172Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# print out the final number of images.\nprint(\"Total number of sketch images:\",len(sketch_arrays))\nprint(\"Total number of images:\",len(image_arrays))","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:02:53.615296Z","iopub.execute_input":"2022-02-25T13:02:53.615796Z","iopub.status.idle":"2022-02-25T13:02:53.622097Z","shell.execute_reply.started":"2022-02-25T13:02:53.615757Z","shell.execute_reply":"2022-02-25T13:02:53.620962Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# defining function to plot images pair\ndef plot_images(image, sketches):\n    plt.figure(figsize=(7,7))\n    plt.subplot(1,2,1)\n    plt.title('Image', color = 'green', fontsize = 20)\n    plt.imshow(image)\n    plt.subplot(1,2,2)\n    plt.title('Sketches ', color = 'black', fontsize = 20)\n    plt.imshow(sketches)\n   \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:02:53.623989Z","iopub.execute_input":"2022-02-25T13:02:53.624353Z","iopub.status.idle":"2022-02-25T13:02:53.631919Z","shell.execute_reply.started":"2022-02-25T13:02:53.624308Z","shell.execute_reply":"2022-02-25T13:02:53.631074Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# displaying images\nls = [i for i in range(0,65,8)]\nfor i in ls:\n    plot_images(image_arrays[i],sketch_arrays[i])","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:02:53.633523Z","iopub.execute_input":"2022-02-25T13:02:53.634176Z","iopub.status.idle":"2022-02-25T13:02:56.205643Z","shell.execute_reply.started":"2022-02-25T13:02:53.634107Z","shell.execute_reply":"2022-02-25T13:02:56.204999Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# this cell splits the arrays obtained into training and testing dataset.\nSIZE = 256\n# 90% of data are assigned to training\ntrain_sketch_image = sketch_arrays[:630]\ntrain_image = image_arrays[:630]\n# 10% of data are assigned to testing\ntest_sketch_image = sketch_arrays[630:]\ntest_image = image_arrays[630:]\n# reshaping\ntrain_sketch_image = np.reshape(train_sketch_image,(len(train_sketch_image),SIZE,SIZE,3))\ntrain_image = np.reshape(train_image, (len(train_image),SIZE,SIZE,3))\nprint('Train color image shape:',train_image.shape)\ntest_sketch_image = np.reshape(test_sketch_image,(len(test_sketch_image),SIZE,SIZE,3))\ntest_image = np.reshape(test_image, (len(test_image),SIZE,SIZE,3))\nprint('Test color image shape',test_image.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:02:56.206997Z","iopub.execute_input":"2022-02-25T13:02:56.207476Z","iopub.status.idle":"2022-02-25T13:02:56.537569Z","shell.execute_reply.started":"2022-02-25T13:02:56.207438Z","shell.execute_reply":"2022-02-25T13:02:56.536805Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# First Model","metadata":{}},{"cell_type":"code","source":"# an early stopping with patience 10 is declared. This is used to avoid overfitting.\nearly_stop = EarlyStopping(monitor=\"val_loss, patience=10\")","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:02:56.539982Z","iopub.execute_input":"2022-02-25T13:02:56.540663Z","iopub.status.idle":"2022-02-25T13:02:56.544677Z","shell.execute_reply.started":"2022-02-25T13:02:56.540622Z","shell.execute_reply":"2022-02-25T13:02:56.543769Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# this is the first model \n# an encoder is created.\nencoder = Sequential()\nencoder.add(Flatten(input_shape=[256,256,3]))\nencoder.add(Dense(64, activation=\"relu\"))\nencoder.add(Dense(32, activation=\"relu\"))\nencoder.add(Dense(16, activation=\"relu\"))\n\n# a decoder is declared.\ndecoder = Sequential()\ndecoder.add(Dense(32, input_shape=[16], activation=\"relu\"))\ndecoder.add(Dense(64, activation=\"relu\"))\ndecoder.add(Dense(256*256*3, activation=\"sigmoid\"))\ndecoder.add(Reshape([256,256,3]))\n\n# both the encoder and decoder are combined to form a autoencoder.\nautoencoder = Sequential([encoder, decoder])\n\n# the model is compiled. \nautoencoder.compile(loss=\"mean_absolute_error\",\n                    optimizer=\"adam\",\n                    metrics=[\"accuracy\"])\n\nautoencoder.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:02:56.550212Z","iopub.execute_input":"2022-02-25T13:02:56.550467Z","iopub.status.idle":"2022-02-25T13:02:59.402142Z","shell.execute_reply.started":"2022-02-25T13:02:56.550434Z","shell.execute_reply":"2022-02-25T13:02:59.400790Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# this function is used to visualize the model.\ntf.keras.utils.plot_model(autoencoder, to_file=\"model_1.png\", show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:02:59.403626Z","iopub.execute_input":"2022-02-25T13:02:59.403884Z","iopub.status.idle":"2022-02-25T13:03:00.244823Z","shell.execute_reply.started":"2022-02-25T13:02:59.403850Z","shell.execute_reply":"2022-02-25T13:03:00.243990Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Model 1 face2sketch","metadata":{}},{"cell_type":"code","source":"# the model is fit.\nhist = autoencoder.fit(train_image, train_sketch_image, epochs=200, verbose=0, validation_data=(test_image, test_sketch_image), callbacks=[early_stop])\n\n# model is evaluated for checking the accuracy. \nprediction_on_test_data = autoencoder.evaluate(test_image, test_sketch_image)\nprint(\"Loss: \", prediction_on_test_data[0])\nprint(\"Accuracy: \", np.round(prediction_on_test_data[1] * 100,1))\n\n# predictions are made on the test data\npred=autoencoder.predict(test_image)\n\n# results are displayed on the test data.\nn =10\nplt.imshow(test_image[n])\nplt.show()\nplt.imshow(test_sketch_image[n])\nplt.show()\nplt.imshow(pred[n].reshape(256,256,3))","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:03:00.246533Z","iopub.execute_input":"2022-02-25T13:03:00.247179Z","iopub.status.idle":"2022-02-25T13:05:25.874631Z","shell.execute_reply.started":"2022-02-25T13:03:00.247123Z","shell.execute_reply":"2022-02-25T13:05:25.873974Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# visualize the loss of the model during taining and testing.\nmetrics = pd.DataFrame(hist.history)\nmetrics[[\"loss\", \"val_loss\"]].plot()","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:05:25.875910Z","iopub.execute_input":"2022-02-25T13:05:25.876671Z","iopub.status.idle":"2022-02-25T13:05:26.140603Z","shell.execute_reply.started":"2022-02-25T13:05:25.876634Z","shell.execute_reply":"2022-02-25T13:05:26.139949Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# this cell is used to calculate the structural similarity of between original and predicted results.\nimageA = test_image[18]\nimageB = pred[18]\n\n# Convert the images to grayscale\ngrayA = cv2.cvtColor(imageA, cv2.COLOR_BGR2GRAY)\ngrayB = cv2.cvtColor(imageB, cv2.COLOR_BGR2GRAY)\n\n# Compute the Structural Similarity Index (SSIM) between the two\n# images, ensuring that the difference image is returned\n(score, diff) = structural_similarity(grayA, grayB, full=True)\ndiff = (diff * 255).astype(\"uint8\")\n\n# You can print only the score if you want\nprint(\"SSIM: {}\".format(score))","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:05:26.141807Z","iopub.execute_input":"2022-02-25T13:05:26.142530Z","iopub.status.idle":"2022-02-25T13:05:26.161267Z","shell.execute_reply.started":"2022-02-25T13:05:26.142493Z","shell.execute_reply":"2022-02-25T13:05:26.160571Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Model 1 sketch2face","metadata":{}},{"cell_type":"code","source":"# the model is fit.\nhist1 = autoencoder.fit(train_sketch_image, train_image, epochs=200, verbose=0, validation_data=(test_sketch_image, test_image), callbacks=[early_stop])\n\n# model is evaluated for checking the accuracy. \nprediction_on_test_data = autoencoder.evaluate(test_sketch_image, test_image)\nprint(\"Loss: \", prediction_on_test_data[0])\nprint(\"Accuracy: \", np.round(prediction_on_test_data[1] * 100,1))\n\n# predictions are made on the test data\npred=autoencoder.predict(test_sketch_image)\n\n# results are displayed on the test data.\nn =10\nplt.imshow(test_image[n])\nplt.show()\nplt.imshow(test_sketch_image[n])\nplt.show()\nplt.imshow(pred[n].reshape(256,256,3))","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:05:26.162542Z","iopub.execute_input":"2022-02-25T13:05:26.162875Z","iopub.status.idle":"2022-02-25T13:07:22.815733Z","shell.execute_reply.started":"2022-02-25T13:05:26.162835Z","shell.execute_reply":"2022-02-25T13:07:22.815071Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# visualize the loss of the model during taining and testing.\nmetrics = pd.DataFrame(hist.history)\nmetrics[[\"loss\", \"val_loss\"]].plot()","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:07:22.824927Z","iopub.execute_input":"2022-02-25T13:07:22.827603Z","iopub.status.idle":"2022-02-25T13:07:23.146044Z","shell.execute_reply.started":"2022-02-25T13:07:22.827563Z","shell.execute_reply":"2022-02-25T13:07:23.145397Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# this cell is used to calculate the structural similarity of between original and predicted results.\nimageA = test_sketch_image[18]\nimageB = pred[18]\n\n# Convert the images to grayscale\ngrayA = cv2.cvtColor(imageA, cv2.COLOR_BGR2GRAY)\ngrayB = cv2.cvtColor(imageB, cv2.COLOR_BGR2GRAY)\n\n# Compute the Structural Similarity Index (SSIM) between the two\n# images, ensuring that the difference image is returned\n(score, diff) = structural_similarity(grayA, grayB, full=True)\ndiff = (diff * 255).astype(\"uint8\")\n\n# You can print only the score if you want\nprint(\"SSIM: {}\".format(score))","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:07:23.147132Z","iopub.execute_input":"2022-02-25T13:07:23.147533Z","iopub.status.idle":"2022-02-25T13:07:23.163377Z","shell.execute_reply.started":"2022-02-25T13:07:23.147495Z","shell.execute_reply":"2022-02-25T13:07:23.162542Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Second Model","metadata":{}},{"cell_type":"code","source":"# this is the second model which is a simple convolution autoencoder.\nmodel=Sequential()\n# input layer\nmodel.add(Conv2D(64, (3,3), activation='relu', padding='same', input_shape=(256,256,3)))\n# pooling layer\nmodel.add(MaxPooling2D((2,2), padding='same'))\n# conv layer\nmodel.add(Conv2D(32, (3,3),activation='relu',padding='same'))\n# pooling layer\nmodel.add(MaxPooling2D((2,2), padding='same'))\n# conv layer\nmodel.add(Conv2D(16, (3,3),activation='relu',padding='same'))\n# pooling layer\nmodel.add(MaxPooling2D((2,2), padding='same'))\n# conv layer decoder side\nmodel.add(Conv2D(16, (3,3), activation='relu', padding='same'))\n# upscaling layer\nmodel.add(UpSampling2D((2,2)))\n# conv layer\nmodel.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n# upscaling layer\nmodel.add(UpSampling2D((2,2)))\n# conv layer\nmodel.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n# upscaling layer\nmodel.add(UpSampling2D((2,2)))\n# conv layer\nmodel.add(Conv2D(3, (3,3), activation='relu', padding='same'))\n\n# model is compiled\nmodel.compile(optimizer=\"adam\",loss='mean_squared_error',metrics=['accuracy'])\n# model.compile(optimizer=\"adam\",loss='binary_crossentropy',metrics=['accuracy'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:07:23.164782Z","iopub.execute_input":"2022-02-25T13:07:23.165100Z","iopub.status.idle":"2022-02-25T13:07:23.270601Z","shell.execute_reply.started":"2022-02-25T13:07:23.165062Z","shell.execute_reply":"2022-02-25T13:07:23.269932Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# this function is used to visualize the model.\ntf.keras.utils.plot_model(model, to_file=\"model_2.png\", show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:07:23.271870Z","iopub.execute_input":"2022-02-25T13:07:23.272099Z","iopub.status.idle":"2022-02-25T13:07:23.549636Z","shell.execute_reply.started":"2022-02-25T13:07:23.272068Z","shell.execute_reply":"2022-02-25T13:07:23.548810Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## Model 2 face2sketch","metadata":{}},{"cell_type":"code","source":"# model is fit\nhist = model.fit(train_image, train_sketch_image, epochs=200, shuffle=True, verbose=0, validation_data=(test_image, test_sketch_image), callbacks=[early_stop])\n\nprediction_on_test_data = model.evaluate(test_image, test_sketch_image)\nprint(\"Loss: \", prediction_on_test_data[0])\nprint(\"Accuracy: \", np.round(prediction_on_test_data[1] * 100,1))\n\n# predictions are made.\npred=model.predict(test_image)\n\n# results are visualized\nn = 10\nplt.imshow(test_image[n])\nplt.show()\nplt.imshow(test_sketch_image[n])\nplt.show()\nplt.imshow(pred[n].reshape(256,256,3))","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:07:23.551274Z","iopub.execute_input":"2022-02-25T13:07:23.551908Z","iopub.status.idle":"2022-02-25T13:14:08.402951Z","shell.execute_reply.started":"2022-02-25T13:07:23.551869Z","shell.execute_reply":"2022-02-25T13:14:08.402035Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# visualize the loss of the model during taining and testing.\nmetrics = pd.DataFrame(hist.history)\nmetrics[[\"loss\", \"val_loss\"]].plot()","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:14:08.404296Z","iopub.execute_input":"2022-02-25T13:14:08.409081Z","iopub.status.idle":"2022-02-25T13:14:08.658178Z","shell.execute_reply.started":"2022-02-25T13:14:08.409024Z","shell.execute_reply":"2022-02-25T13:14:08.656932Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# this cell is used to calculate the structural similarity of between original and predicted results.\nimageA = test_image[18]\nimageB = pred[18]\n\n# Convert the images to grayscale\ngrayA = cv2.cvtColor(imageA, cv2.COLOR_BGR2GRAY)\ngrayB = cv2.cvtColor(imageB, cv2.COLOR_BGR2GRAY)\n\n# Compute the Structural Similarity Index (SSIM) between the two\n# images, ensuring that the difference image is returned\n(score, diff) = structural_similarity(grayA, grayB, full=True)\ndiff = (diff * 255).astype(\"uint8\")\n\n# You can print only the score if you want\nprint(\"SSIM: {}\".format(score))","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:14:08.659602Z","iopub.execute_input":"2022-02-25T13:14:08.660514Z","iopub.status.idle":"2022-02-25T13:14:08.677205Z","shell.execute_reply.started":"2022-02-25T13:14:08.660474Z","shell.execute_reply":"2022-02-25T13:14:08.676465Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## Model 2 sketch2face","metadata":{}},{"cell_type":"code","source":"# model is fit\nhist = model.fit(train_sketch_image, train_image, epochs=100, shuffle=True, verbose=0, validation_data=(test_sketch_image, test_image), callbacks=[early_stop])\n\nprediction_on_test_data = model.evaluate(test_sketch_image, test_image)\nprint(\"Loss: \", prediction_on_test_data[0])\nprint(\"Accuracy: \", np.round(prediction_on_test_data[1] * 100,1))\n\n# predictions are made on testing data\npred=model.predict(test_sketch_image)\n\n# results are visualized\nn = 10\nplt.imshow(test_image[n])\nplt.show()\nplt.imshow(test_sketch_image[n])\nplt.show()\nplt.imshow(pred[n].reshape(256,256,3))","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:14:08.678563Z","iopub.execute_input":"2022-02-25T13:14:08.679473Z","iopub.status.idle":"2022-02-25T13:17:28.976576Z","shell.execute_reply.started":"2022-02-25T13:14:08.679435Z","shell.execute_reply":"2022-02-25T13:17:28.975925Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# visualize the loss of the model during taining and testing.\nmetrics = pd.DataFrame(hist.history)\nmetrics[[\"loss\", \"val_loss\"]].plot()","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:17:28.977863Z","iopub.execute_input":"2022-02-25T13:17:28.978249Z","iopub.status.idle":"2022-02-25T13:17:29.221560Z","shell.execute_reply.started":"2022-02-25T13:17:28.978213Z","shell.execute_reply":"2022-02-25T13:17:29.220105Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"imageA = test_sketch_image[18]\nimageB = pred[18]\n\n# Convert the images to grayscale\ngrayA = cv2.cvtColor(imageA, cv2.COLOR_BGR2GRAY)\ngrayB = cv2.cvtColor(imageB, cv2.COLOR_BGR2GRAY)\n\n# Compute the Structural Similarity Index (SSIM) between the two\n# images, ensuring that the difference image is returned\n(score, diff) = structural_similarity(grayA, grayB, full=True)\ndiff = (diff * 255).astype(\"uint8\")\n\n# You can print only the score if you want\nprint(\"SSIM: {}\".format(score))","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:17:29.223064Z","iopub.execute_input":"2022-02-25T13:17:29.224086Z","iopub.status.idle":"2022-02-25T13:17:29.240443Z","shell.execute_reply.started":"2022-02-25T13:17:29.224048Z","shell.execute_reply":"2022-02-25T13:17:29.239699Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"# Third Model","metadata":{}},{"cell_type":"code","source":"# the third model is also a convolution autoencoder but with a but if complexity\n# the downsampled function is defined. defining the encoder side of autoencoder.\ndef downsample(filters, size, apply_batch_normalization = True):\n    downsample = Sequential()\n    # a conv layer\n    downsample.add(tensorflow.keras.layers.Conv2D(filters = filters, kernel_size = size, strides = 2, use_bias = False, kernel_initializer = 'he_normal'))\n    # provisions to apply batch normalization\n    if apply_batch_normalization:\n        downsample.add(tensorflow.keras.layers.BatchNormalization())\n    downsample.add(tensorflow.keras.layers.LeakyReLU())\n    return downsample\n\n# the upsample function is defined. defining the decoder side of autoencoder.\ndef upsample(filters, size, apply_dropout = False):\n    upsample = Sequential()\n    # a conv layer\n    upsample.add(tensorflow.keras.layers.Conv2DTranspose(filters = filters, kernel_size = size, strides = 2, use_bias = False, kernel_initializer = 'he_normal'))\n    if apply_dropout:\n        # provisions to apply dropout\n        upsample.add(tensorflow.keras.layers.Dropout(0.1))\n    upsample.add(tensorflow.keras.layers.LeakyReLU()) \n    return upsample\n\n# the model is defined here\ndef model():\n    # input layer\n    encoder_input = tensorflow.keras.Input(shape = (SIZE, SIZE, 3))\n    # layers of encoder.\n    x = downsample(16, 4, False)(encoder_input)\n    x = downsample(32,4)(x)\n    x = downsample(64,4,True)(x)\n    x = downsample(128,4)(x)\n    x = downsample(256,4)(x)\n   \n    encoder_output = downsample(512,4)(x)\n    \n    decoder_input = upsample(512,4,True)(encoder_output)\n    # layers of decoder\n    x = upsample(256,4,False)(decoder_input)\n    x = upsample(128,4, True)(x)\n    x = upsample(64,4)(x)\n    x = upsample(32,4)(x)\n    x = upsample(16,4)(x)\n    x = tensorflow.keras.layers.Conv2DTranspose(8,(2,2),strides = (1,1), padding = 'valid')(x)\n    decoder_output = tensorflow.keras.layers.Conv2DTranspose(3,(2,2),strides = (1,1), padding = 'valid')(x)\n    \n    # the encoder and decoder is combined to make the autoencoder\n    return tensorflow.keras.Model(encoder_input, decoder_output)\n\n\nmodel = model()\nmodel.summary()\n# model is compiled\nmodel.compile(optimizer = tensorflow.keras.optimizers.Adam(learning_rate = 0.001), loss = 'mean_absolute_error',\n              metrics = ['acc'])","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:17:29.242070Z","iopub.execute_input":"2022-02-25T13:17:29.242914Z","iopub.status.idle":"2022-02-25T13:17:29.892742Z","shell.execute_reply.started":"2022-02-25T13:17:29.242870Z","shell.execute_reply":"2022-02-25T13:17:29.891968Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model, to_file=\"model_3.png\", show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:17:29.894592Z","iopub.execute_input":"2022-02-25T13:17:29.894832Z","iopub.status.idle":"2022-02-25T13:17:30.224038Z","shell.execute_reply.started":"2022-02-25T13:17:29.894797Z","shell.execute_reply":"2022-02-25T13:17:30.223213Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"## Model 3 face2sketch","metadata":{}},{"cell_type":"code","source":"# model is fit\nhist = model.fit(train_image, train_sketch_image, epochs=200, shuffle=True, verbose=0, validation_data=(test_image, test_sketch_image), callbacks=[early_stop])\n\nprediction_on_test_data = model.evaluate(test_image, test_sketch_image)\nprint(\"Loss: \", prediction_on_test_data[0])\nprint(\"Accuracy: \", np.round(prediction_on_test_data[1] * 100,1))\n\n# predictions are made on testing data\npred=model.predict(test_image)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:17:30.230991Z","iopub.execute_input":"2022-02-25T13:17:30.231634Z","iopub.status.idle":"2022-02-25T13:22:42.502113Z","shell.execute_reply.started":"2022-02-25T13:17:30.231595Z","shell.execute_reply":"2022-02-25T13:22:42.501314Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"n = 18\nplt.imshow(test_image[n])\nplt.show()\nplt.imshow(test_sketch_image[n])\nplt.show()\nplt.imshow(pred[n].reshape(256,256,3))","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:22:42.528024Z","iopub.execute_input":"2022-02-25T13:22:42.528627Z","iopub.status.idle":"2022-02-25T13:22:43.210762Z","shell.execute_reply.started":"2022-02-25T13:22:42.528590Z","shell.execute_reply":"2022-02-25T13:22:43.210016Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# loss is visualized\nmetrics = pd.DataFrame(hist.history)\nmetrics[[\"loss\", \"val_loss\"]].plot()","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:22:43.212265Z","iopub.execute_input":"2022-02-25T13:22:43.212812Z","iopub.status.idle":"2022-02-25T13:22:43.461726Z","shell.execute_reply.started":"2022-02-25T13:22:43.212775Z","shell.execute_reply":"2022-02-25T13:22:43.460968Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"imageA = test_image[18]\nimageB = pred[18]\n\n# Convert the images to grayscale\ngrayA = cv2.cvtColor(imageA, cv2.COLOR_BGR2GRAY)\ngrayB = cv2.cvtColor(imageB, cv2.COLOR_BGR2GRAY)\n\n# Compute the Structural Similarity Index (SSIM) between the two\n# images, ensuring that the difference image is returned\n(score, diff) = structural_similarity(grayA, grayB, full=True)\ndiff = (diff * 255).astype(\"uint8\")\n\n# You can print only the score if you want\nprint(\"SSIM: {}\".format(score))","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:22:43.463236Z","iopub.execute_input":"2022-02-25T13:22:43.463799Z","iopub.status.idle":"2022-02-25T13:22:43.478958Z","shell.execute_reply.started":"2022-02-25T13:22:43.463762Z","shell.execute_reply":"2022-02-25T13:22:43.478190Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"## Model 3 sketch2face","metadata":{}},{"cell_type":"code","source":"# model is fit\nhist = model.fit(train_sketch_image, train_image, epochs=200, shuffle=True, verbose=0, validation_data=(test_sketch_image, test_image), callbacks=[early_stop])\n\nprediction_on_test_data = model.evaluate(test_sketch_image, test_image)\nprint(\"Loss: \", prediction_on_test_data[0])\nprint(\"Accuracy: \", np.round(prediction_on_test_data[1] * 100,1))\n\n# predictions are made\npred=model.predict(test_sketch_image)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:22:43.480563Z","iopub.execute_input":"2022-02-25T13:22:43.481280Z","iopub.status.idle":"2022-02-25T13:27:52.624162Z","shell.execute_reply.started":"2022-02-25T13:22:43.481230Z","shell.execute_reply":"2022-02-25T13:27:52.623489Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"n = 18\nplt.imshow(test_image[n])\nplt.show()\nplt.imshow(test_sketch_image[n])\nplt.show()\nplt.imshow(pred[n].reshape(256,256,3))","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:27:52.625497Z","iopub.execute_input":"2022-02-25T13:27:52.625755Z","iopub.status.idle":"2022-02-25T13:27:53.326835Z","shell.execute_reply.started":"2022-02-25T13:27:52.625726Z","shell.execute_reply":"2022-02-25T13:27:53.326184Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# loss is visualized\nmetrics = pd.DataFrame(hist.history)\nmetrics[[\"loss\", \"val_loss\"]].plot()","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:27:53.328109Z","iopub.execute_input":"2022-02-25T13:27:53.329320Z","iopub.status.idle":"2022-02-25T13:27:53.566672Z","shell.execute_reply.started":"2022-02-25T13:27:53.328999Z","shell.execute_reply":"2022-02-25T13:27:53.566036Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"imageA = test_sketch_image[18]\nimageB = pred[18]\n\n# Convert the images to grayscale\ngrayA = cv2.cvtColor(imageA, cv2.COLOR_BGR2GRAY)\ngrayB = cv2.cvtColor(imageB, cv2.COLOR_BGR2GRAY)\n\n# Compute the Structural Similarity Index (SSIM) between the two\n# images, ensuring that the difference image is returned\n(score, diff) = structural_similarity(grayA, grayB, full=True)\ndiff = (diff * 255).astype(\"uint8\")\n\n# You can print only the score if you want\nprint(\"SSIM: {}\".format(score))","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:27:53.568032Z","iopub.execute_input":"2022-02-25T13:27:53.568620Z","iopub.status.idle":"2022-02-25T13:27:53.584750Z","shell.execute_reply.started":"2022-02-25T13:27:53.568576Z","shell.execute_reply":"2022-02-25T13:27:53.584042Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"# Fourth Model","metadata":{}},{"cell_type":"code","source":"model1=Sequential()\n\nmodel1.add(Conv2D(64, (3,3), activation='relu', padding='same', input_shape=(256,256,3)))\nmodel1.add(MaxPooling2D((2,2), padding='same'))\nmodel1.add(Conv2D(32, (3,3),activation='relu',padding='same'))\nmodel1.add(MaxPooling2D((2,2), padding='same'))\nmodel1.add(Conv2D(16, (3,3),activation='relu',padding='same'))\nmodel1.add(MaxPooling2D((2,2), padding='same'))\n\nmodel1.add(Conv2D(16, (3,3), activation='relu', padding='same'))\nmodel1.add(UpSampling2D((2,2)))\n\nmodel1.add(Conv2D(32, (3,3), activation='relu', padding='same'))\nmodel1.add(UpSampling2D((2,2)))\n\nmodel1.add(Conv2D(64, (3,3), activation='relu', padding='same'))\nmodel1.add(UpSampling2D((2,2)))\n\nmodel1.add(Conv2D(3, (3,3), activation='relu', padding='same'))\n\ndef downsample(filters, size, apply_batch_normalization = True):\n    downsample = Sequential()\n    downsample.add(tensorflow.keras.layers.Conv2D(filters = filters, kernel_size = size, strides = 2, use_bias = False, kernel_initializer = 'he_normal'))\n    if apply_batch_normalization:\n        downsample.add(tensorflow.keras.layers.BatchNormalization())\n    downsample.add(tensorflow.keras.layers.LeakyReLU())\n    return downsample\n\ndef upsample(filters, size, apply_dropout = False):\n    upsample = Sequential()\n    upsample.add(tensorflow.keras.layers.Conv2DTranspose(filters = filters, kernel_size = size, strides = 2, use_bias = False, kernel_initializer = 'he_normal'))\n    if apply_dropout:\n        upsample.add(tensorflow.keras.layers.Dropout(0.1))\n    upsample.add(tensorflow.keras.layers.LeakyReLU()) \n    return upsample\n\ndef model2():\n    encoder_input = tensorflow.keras.Input(shape = (SIZE, SIZE, 3))\n    x = downsample(16, 4, False)(encoder_input)\n    x = downsample(32,4)(x)\n    x = downsample(64,4,False)(x)\n    x = downsample(128,4)(x)\n    x = downsample(256,4)(x)\n   \n    encoder_output = downsample(512,4)(x)\n    \n    decoder_input = upsample(512,4,True)(encoder_output)\n    x = upsample(256,4,False)(decoder_input)\n    x = upsample(128,4, True)(x)\n    x = upsample(64,4)(x)\n    x = upsample(32,4)(x)\n    x = upsample(16,4)(x)\n    x = tensorflow.keras.layers.Conv2DTranspose(8,(2,2),strides = (1,1), padding = 'valid')(x)\n    decoder_output = tensorflow.keras.layers.Conv2DTranspose(3,(2,2),strides = (1,1), padding = 'valid')(x)\n    \n  \n    return tensorflow.keras.Model(encoder_input, decoder_output)\n\nmodel2 = model2()\n\nencoder = Sequential()\nencoder.add(Flatten(input_shape=[256,256,3]))\nencoder.add(Dense(64, activation=\"relu\"))\nencoder.add(Dense(32, activation=\"relu\"))\nencoder.add(Dense(16, activation=\"relu\"))\n\ndecoder = Sequential()\ndecoder.add(Dense(32, input_shape=[16], activation=\"relu\"))\ndecoder.add(Dense(64, activation=\"relu\"))\ndecoder.add(Dense(256*256*3, activation=\"sigmoid\"))\ndecoder.add(Reshape([256,256,3]))\n\nmodel3 = Sequential([encoder, decoder])\n\n# a common input is given to all models.\ncommonInput = Input(shape=(256,256,3))\n\n# three models are given the same imput.\nout1 = model1(commonInput)    \nout2 = model2(commonInput)  \nout3 = model3(commonInput)\n\n# the three models are added together\nmergedOut = Add()([out1,out2,out3])\n\n# a final ensemble model is created.\noneInputModel = Model(commonInput,mergedOut)\n\n# ensemble model is compiled.\noneInputModel.compile(optimizer=\"adam\",loss='mean_absolute_error',metrics=['accuracy'])\noneInputModel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:27:53.586438Z","iopub.execute_input":"2022-02-25T13:27:53.587171Z","iopub.status.idle":"2022-02-25T13:27:54.199926Z","shell.execute_reply.started":"2022-02-25T13:27:53.587105Z","shell.execute_reply":"2022-02-25T13:27:54.198997Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model, to_file=\"model_4.png\", show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:27:54.201433Z","iopub.execute_input":"2022-02-25T13:27:54.201754Z","iopub.status.idle":"2022-02-25T13:27:54.679562Z","shell.execute_reply.started":"2022-02-25T13:27:54.201710Z","shell.execute_reply":"2022-02-25T13:27:54.672399Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"## Model 4 sketch2face","metadata":{}},{"cell_type":"code","source":"# model is fit\nhist = oneInputModel.fit(train_sketch_image, train_image, epochs=200, shuffle=True, verbose=0, validation_data=(test_sketch_image, test_image), callbacks=[early_stop])\n\nprediction_on_test_data = oneInputModel.evaluate(test_sketch_image, test_image)\nprint(\"Loss: \", prediction_on_test_data[0])\nprint(\"Accuracy: \", np.round(prediction_on_test_data[1] * 100,1))\n\n# predictions are made.\npred=oneInputModel.predict(test_sketch_image)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:27:54.681509Z","iopub.execute_input":"2022-02-25T13:27:54.682327Z","iopub.status.idle":"2022-02-25T13:38:42.770071Z","shell.execute_reply.started":"2022-02-25T13:27:54.682287Z","shell.execute_reply":"2022-02-25T13:38:42.769250Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# results are visualized\nn=18\nplt.imshow(test_image[n])\nplt.show()\nplt.imshow(test_sketch_image[n])\nplt.show()\nplt.imshow(pred[n].reshape(256,256,3))","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:38:42.771701Z","iopub.execute_input":"2022-02-25T13:38:42.771963Z","iopub.status.idle":"2022-02-25T13:38:43.436891Z","shell.execute_reply.started":"2022-02-25T13:38:42.771925Z","shell.execute_reply":"2022-02-25T13:38:43.436229Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# loss is visualized\nmetrics = pd.DataFrame(hist.history)\nmetrics[[\"loss\", \"val_loss\"]].plot()","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:38:43.438486Z","iopub.execute_input":"2022-02-25T13:38:43.442700Z","iopub.status.idle":"2022-02-25T13:38:43.792634Z","shell.execute_reply.started":"2022-02-25T13:38:43.442656Z","shell.execute_reply":"2022-02-25T13:38:43.792013Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"imageA = test_image[18]\nimageB = pred[18]\n\n# 4. Convert the images to grayscale\ngrayA = cv2.cvtColor(imageA, cv2.COLOR_BGR2GRAY)\ngrayB = cv2.cvtColor(imageB, cv2.COLOR_BGR2GRAY)\n\n# 5. Compute the Structural Similarity Index (SSIM) between the two\n#    images, ensuring that the difference image is returned\n(score, diff) = structural_similarity(grayA, grayB, full=True)\ndiff = (diff * 255).astype(\"uint8\")\n\n# 6. You can print only the score if you want\nprint(\"SSIM: {}\".format(score))","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:38:43.794061Z","iopub.execute_input":"2022-02-25T13:38:43.794967Z","iopub.status.idle":"2022-02-25T13:38:43.828810Z","shell.execute_reply.started":"2022-02-25T13:38:43.794929Z","shell.execute_reply":"2022-02-25T13:38:43.828189Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"## Mode 4 face2sketch","metadata":{}},{"cell_type":"code","source":"# model is fit\nhist = oneInputModel.fit(train_image,train_sketch_image, epochs=200, shuffle=True, verbose=0, validation_data=(test_image, test_sketch_image), callbacks=[early_stop])\n\nprediction_on_test_data = oneInputModel.evaluate(test_image, test_sketch_image)\nprint(\"Loss: \", prediction_on_test_data[0])\nprint(\"Accuracy: \", np.round(prediction_on_test_data[1] * 100,1))\n\n# predictions are made.\npred=oneInputModel.predict(test_image)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:38:43.829659Z","iopub.execute_input":"2022-02-25T13:38:43.829903Z","iopub.status.idle":"2022-02-25T13:49:30.444390Z","shell.execute_reply.started":"2022-02-25T13:38:43.829871Z","shell.execute_reply":"2022-02-25T13:49:30.443621Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# results are visualized\nn=18\nplt.imshow(test_image[n])\nplt.show()\nplt.imshow(test_sketch_image[n])\nplt.show()\nplt.imshow(pred[n].reshape(256,256,3))","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:49:30.445656Z","iopub.execute_input":"2022-02-25T13:49:30.445933Z","iopub.status.idle":"2022-02-25T13:49:31.111638Z","shell.execute_reply.started":"2022-02-25T13:49:30.445895Z","shell.execute_reply":"2022-02-25T13:49:31.110984Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# loss is visualized\nmetrics = pd.DataFrame(hist.history)\nmetrics[[\"loss\", \"val_loss\"]].plot()","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:49:31.113115Z","iopub.execute_input":"2022-02-25T13:49:31.113692Z","iopub.status.idle":"2022-02-25T13:49:31.342558Z","shell.execute_reply.started":"2022-02-25T13:49:31.113656Z","shell.execute_reply":"2022-02-25T13:49:31.340981Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"imageA = test_image[18]\nimageB = pred[18]\n\n# 4. Convert the images to grayscale\ngrayA = cv2.cvtColor(imageA, cv2.COLOR_BGR2GRAY)\ngrayB = cv2.cvtColor(imageB, cv2.COLOR_BGR2GRAY)\n\n# 5. Compute the Structural Similarity Index (SSIM) between the two\n#    images, ensuring that the difference image is returned\n(score, diff) = structural_similarity(grayA, grayB, full=True)\ndiff = (diff * 255).astype(\"uint8\")\n\n# 6. You can print only the score if you want\nprint(\"SSIM: {}\".format(score))","metadata":{"execution":{"iopub.status.busy":"2022-02-25T13:49:31.344024Z","iopub.execute_input":"2022-02-25T13:49:31.344906Z","iopub.status.idle":"2022-02-25T13:49:31.359386Z","shell.execute_reply.started":"2022-02-25T13:49:31.344865Z","shell.execute_reply":"2022-02-25T13:49:31.358606Z"},"trusted":true},"execution_count":45,"outputs":[]}]}